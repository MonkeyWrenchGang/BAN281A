{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- besure to put the title, name, email and date here in a markdown cell! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages\n",
    "-------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import clear_output\n",
    "display(HTML(\"<style>.container { width:90% }</style>\"))\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# -- sklearn modules \n",
    "from sklearn.model_selection import train_test_split # - splits data into training and test sets \n",
    "from sklearn.metrics import accuracy_score           # - calculates accuracy \n",
    "\n",
    "# -- need this to render charts in notebook -- \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1\n",
    "You are a newly minted data scientist working for a telecommunication company like Verizon or ATT. You have been tasked with identify which customers are likely to ‚Äúchurn‚Äù. Customer churn, also known as customer attrition, occurs when customers stop doing business with a company or stop using a company‚Äôs services. Your task is to explore the data and identify some business rules which can help the company identify likely churners. The following Tasks have been dived into Three(3) parts, simply look at the section's **Todos** for your project's required tasks. If there is a question, simply add a markdown cell and answer the question. As always feel free to add additional cells and analysis as you dig into the data.  \n",
    "\n",
    "\n",
    "### Part 1\n",
    "1. Stage data\n",
    "2. Clean up column names \n",
    "3. Describe data \n",
    "4. Explore likely predictors  \n",
    "\n",
    "### Part 2.\n",
    "5. Partition into 75/25 split \n",
    "6. Write a rule to predict likely targets \n",
    "7. Evaluate  \n",
    "\n",
    "### Part 3.  \n",
    "8. Write up your thoughts, in a markdown cell. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. \n",
    "## 1. Stage \n",
    "----- \n",
    "Import our dataset into a pandas dataframe\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"> üí° <strong> TODO </strong>\n",
    " \n",
    "1. Read churn.csv into a dataframe named df \n",
    "2. use df.head() to display the first 5 records \n",
    "</div>\n",
    "\n",
    "```python\n",
    "\n",
    "df = pd.read_csv(\"./data/adult.csv\")\n",
    "df.head()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Clean up Column Names\n",
    "\n",
    "*It's just not fun dealing with ill-formed columns*\n",
    "\n",
    "<div class=\"alert alert-info\"> üí° <strong> TODO </strong>\n",
    " \n",
    "1. clean names \n",
    "    - remove leading and trailing characters\n",
    "    - replace spaces with underscores _ \n",
    "    - change case to lower case\n",
    "    - remove various special characters\n",
    "2. print column names \n",
    "3. use head to display first 5 records \n",
    "\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "**Todo:**\n",
    "\n",
    "\n",
    "This is how I clean up column names. \n",
    "\n",
    "```python\n",
    "df.columns = ( df.columns\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .str.replace(' ', '_')\n",
    "    .str.replace('-', '_')\n",
    "    .str.replace('(', '')\n",
    "    .str.replace(')', '')\n",
    "    .str.replace('?', '')\n",
    "    .str.replace('\\'', '') # notice the backslash \\ this is an escape character\n",
    ")\n",
    "print(df.columns)\n",
    "df.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ( df.columns\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .str.replace(' ', '_')\n",
    "    .str.replace('-', '_')\n",
    "    .str.replace('(', '')\n",
    "    .str.replace(')', '')\n",
    "    .str.replace('?', '')\n",
    "    .str.replace('\\'', '') # notice the backslash \\ this is an escape character\n",
    ")\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Describe data\n",
    "### Check Target Distribution \n",
    "\n",
    "-----\n",
    "Always start by understanding your **\"target\"** column this will determine how you are going to perform your analysis \n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"> üí° <strong> TODO </strong>\n",
    " \n",
    "1. use value_counts on churn column to display count \n",
    "2. use value_counts but normalize the results so you get percentages \n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "df['income'].value_counts()               # - perform counts \n",
    "df['income'].value_counts(normalize=True) # return percentages \n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe \n",
    "---------\n",
    "Always take a look at your data to see what you are dealing with. I recomend using describe and dtypes to understand what i've just imported. \n",
    "<div class=\"alert alert-info\"> üí° <strong> TODO </strong>\n",
    " \n",
    "\n",
    "\n",
    "1. use describe to print out descriptive statitiscs, what does T do and what does sort_values do? \n",
    "2. use dtypes to output data types, what is an object data type. are their numbers that should be considered categorical? think area codes\n",
    "</div>\n",
    "\n",
    "\n",
    "```python\n",
    "df.describe(include='all').T.sort_values('unique')\n",
    "df.dtypes\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out Nulls \n",
    "----\n",
    "Null values can be interesting but you have to deal with them when we get to building models. \n",
    "\n",
    "**Step 1. is to identify your problem areas.**  \n",
    "\n",
    "Step 2. figure out if there is any predictive power in the nulls - not necesary here! \n",
    "\n",
    "Step 3. handle them. - not necessary yet! \n",
    "\n",
    "<div class=\"alert alert-info\"> üí° <strong> TODO </strong>\n",
    " \n",
    "1. Identify if any columns contain nulls. \n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "# -- count nulls by column -- \n",
    "df.isnull().sum(axis = 0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore likely predictors\n",
    "### Make Histograms, Crosstabs and Barcharts \n",
    "\n",
    "Because you are new to plots and graphs in python i'll do the first couple for you. Your job is to do the following.\n",
    "\n",
    "Todo: \n",
    "\n",
    "<div class=\"alert alert-info\"> üí° <strong> TODO </strong>\n",
    " \n",
    "1. Histogram 1 - Pick a *NUMERIC* column that you think might be useful and make a histogram. \n",
    "    - make sure you have one color for churn == True and another for churn == False. \n",
    "2. Histogram 2 - Pick a *Second NUMERIC* column that you think might be useful \n",
    "    - make sure you have one color for churn == True and another for churn == False. \n",
    "3. Barchart 1 - Pick a *CHARACTER* column that you think might be useful \n",
    "    - 1a. make sure you have counts and that you can overlay them. \n",
    "    - 1b. make sure you use normalize=\"index\" to get percentages and that you can overlay them, and use bottom= \n",
    "4. Barchart 2 - Pick a *Second CHARACTER* column that you think might be useful \n",
    "    - 1a. make sure you have counts and that you can overlay them. \n",
    "    - 1b. make sure you use normalize=\"index\" to get percentages and that you can overlay them, and use bottom= \n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "See examples below\n",
    "\n",
    "\n",
    "----- \n",
    "\n",
    "We are looking to identify variables, split points and conditions that are likely useful to predict our target. \n",
    "\n",
    "Here is my basic recipe. \n",
    "1. Use histograms on NUMERIC varaibles, mess with the number of bins to make a more interesting chart. \n",
    "    - filter for churn == True. and another for churn == False. \n",
    "    - use two plt.hist to get them to overlay. \n",
    "2. Use the crosstab + barchart recipe to create a table of frequencies for CATEGORICAL variables, you may want to normalize or not, i do both. \n",
    "    - first create a cross tab column by target, use reset_index() to return a dataframe instead of a crosstab \n",
    "    - second plot using a BAR chart(s) i typically usae one for each target variable \n",
    "    - if you want to get fancy you can use the bottom option for one of your \n",
    "    \n",
    "```python\n",
    "\n",
    "# -- simple histogram -- \n",
    "plt.figure(figsize=(20,10)) # -- controls the figure size \n",
    "plt.hist(df['day_mins'], 50, facecolor='blue', alpha=0.5) # -- makes the histogram, 50 is the number of bins  \n",
    "plt.title('Title of Chart')\n",
    "plt.ylabel('Y label')\n",
    "plt.xlabel('X label')\n",
    "plt.show() # -- this shows the histogram in the notebook. \n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- simple histogram, not what we want! \n",
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(df['day_mins'], 50, facecolor='blue', alpha=0.5)\n",
    "plt.title('Histogram of Day Minutes')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('day_mins')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- this is what we want for our histograms! \n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "# -- divide my data into two datasets by target variable \n",
    "churn_t = df.loc[df['churn']== \"True.\"]\n",
    "churn_f = df.loc[df['churn']== \"False.\"]\n",
    "\n",
    "# -- simply change the bin size to make the chart look better --\n",
    "plt.hist(churn_t['night_charge'], 25, facecolor='red', alpha=0.5)\n",
    "plt.hist(churn_f['night_charge'], 25, facecolor='lightblue', alpha=0.5)\n",
    "plt.title('Histogram of Day Night Charge')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('night_charge')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Histogram 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Histogram 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OK what about Categorical Data? \n",
    "\n",
    "-----\n",
    "\n",
    "First use a crosstab to create a new table of the column by the target. you can read about crosstabs here \n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.crosstab.html\n",
    "\n",
    "Can you understand the difference when we look at percentages rather than counts? what does this tell us about identifying high earners? \n",
    "\n",
    "<div class=\"alert alert-success\"> üí° <strong> Note </strong>\n",
    "    \n",
    "I'm going to create an example of what i expect for your bar charts. you essentially create two barcharts one on the frequcncy and another by the row percentage. what we are looking for are categories that can be useful to identify churn not churn. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 1st do the Frequencies \n",
    "ctab = pd.crosstab(df['state'], df['churn']).reset_index()\n",
    "ctab.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - then plot it \n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.bar(ctab['state'], ctab['False.'], facecolor='lightblue', alpha=0.5)\n",
    "plt.bar(ctab['state'], ctab['True.'], facecolor='red', alpha=0.5)\n",
    "plt.title('Frequency of Churn by State')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('state')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- 2nd Normalize and Sort  \n",
    "ctab = pd.crosstab(df['state'], df['churn'], normalize=\"index\").reset_index().sort_values('True.',ascending=False )\n",
    "ctab.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - then plot that, but this time use bottom on one of the bar charts \n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "# -- use bottom to stack the bars. since it's sorted you get a nice trend. \n",
    "plt.bar(ctab['state'], ctab['False.'], facecolor='lightblue', alpha=0.5)\n",
    "plt.bar(ctab['state'], ctab['True.'], bottom= ctab['False.'], facecolor='red', alpha=0.5)\n",
    "plt.title('Frequency of Churn by State')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('state')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- crosstab 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- barchart 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- crosstab 1b with normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- barchart 1b with bottom "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- crosstab 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- barchart 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- crosstab 2b with normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- barchart 2b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.\n",
    "### 5. Partition into 75/25 split\n",
    "-----\n",
    "Sklearn is our main pakage, we imported **train_test_split** from the model selection module. Why do we need to split the data? well we do it so that we are making predictions on an out-of-sample data, meaning will our prediction generalize to new and unseen data? it isn't fair to evaluate our prediction if it's seen the data before right? i mean you wouldn't go to your psychic and tell them exactly what you want to hear before they do your the reading?\n",
    "\n",
    "So what percentage to use? the general rule of thumb is a 70/30 or 75/25 training test split. you'll \"train\" your model on 70% of the data and evaluate it on 30%. \n",
    "\n",
    "<div class=\"alert alert-info\"> üí° <strong> TODO </strong>\n",
    "    \n",
    "1. partition your data into a 70/30 split, using train_test_split  \n",
    "2. print the percentages \n",
    "    \n",
    " </div>\n",
    "\n",
    "```python\n",
    "train, test = train_test_split(df,test_size=0.30)\n",
    "print(\"train pct: {:2.2%}\".format(train.shape[0]/df.shape[0]))\n",
    "print(\"test  pct: {:2.2%}\".format(test.shape[0]/df.shape[0]))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Write a rule to predict likely targets\n",
    "-----\n",
    "based on our exploratory analysis above you should have identified one or two rules which \"MIGHT\" be useful \n",
    "\n",
    "This is the recipe. \n",
    "\n",
    "1. Make a new column **churn_pred** default it to False., our majority class \n",
    "2. Write rules to update **churn_pred** to equal True. \n",
    "3. I like confusion matricies they help you know how well you are doing, predicting the target. \n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\"> üí° <strong> TODO </strong>\n",
    "    \n",
    "1. create a new column on training data \"churn_pred\" and DEFAULT it to False. \n",
    "2. write your rules to set \"churn_pred\" to True. \n",
    "3. Create *\"confusion_matrix\"* by using pd.crosstab(actual,predicted)  this one has the counts\n",
    "    - print your confusion matrix \n",
    "    - plot it using a sns heatmap\n",
    "4. Create *\"confusion_matrix_pct\"* by using pd.crosstab(actual,predicted, normalize=\"index\") this one has the percents \n",
    "    - print your confusion matrix \n",
    "    - plot it using a sns heatmap\n",
    "    \n",
    "5. Repeat steps 1-4 for the **test dataset** !!!! \n",
    " </div>\n",
    " \n",
    "```python \n",
    "# 1. -- default the predicted target \n",
    "train.loc[:,'churn_pred'] = 'False.'\n",
    "\n",
    "# 2. -- update where rules are met, use your rules \n",
    "train.loc[train['state'].isin(['CA','TX']), 'churn_pred' ] = 'True.'  # -- this is a single rule \n",
    "\n",
    "# 3 & 4 - confusion matricies and sns heatmap plots. \n",
    "confusion_matrix = pd.crosstab(train['churn'], train['churn_pred'],  rownames=['Actual'], colnames=['Predicted'])\n",
    "confusion_matrix_pct = pd.crosstab(train['churn'], train['churn_pred'], normalize=\"index\", rownames=['Actual'], colnames=['Predicted'])\n",
    "print(\"Training confusion Matrix\")\n",
    "print (confusion_matrix)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='g')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.heatmap(confusion_matrix_pct, annot=True, fmt='g')\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- do this with the TRAIN dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- repeat with the TEST dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate\n",
    "\n",
    "How accurate were we? Accuracy is one metric for evaluating classification models. Informally, accuracy is the fraction of predictions our model got right. \n",
    "Formally, accuracy has the following definition:\n",
    "\n",
    "    accuracy = number of correct predictions / all predictions \n",
    "    \n",
    "    \n",
    "We always want to understand if we did nothing, how accurate were we? and then compare how accurate were we with our predictions. \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "\n",
    "<div class=\"alert alert-info\"> üí° <strong> TODO </strong>\n",
    "\n",
    "1. calculate default accuracy, as if everything were predicted false \n",
    "2. calculate training accuracy, based on your busienss rules applied to the train dataset \n",
    "3. calculate testing accuracy, based on your business rules applied to the test dataset \n",
    "4. answer these questions. \n",
    "    - do you think accuracy a good measure of prediction? \n",
    "    - how would your analysis change if you made $100 for every correct churn==True prediction and -$20 for every missed churn? \n",
    "    \n",
    "</div>\n",
    "\n",
    "```python \n",
    "\n",
    "### Default Accuracy, i.e. do nothing predict everyone as <50K, is the same as saying what % of <50K \n",
    "accuracy_default = train['churn'].value_counts(normalize='True')[0]\n",
    "accuracy_train = accuracy_score(train['churn'], train['churnpred'])\n",
    "accuracy_test = accuracy_score(test['churn'], test['churn_pred'])\n",
    "print(\"Default Accuracy : {:2.2%}\".format(accuracy_default))\n",
    "print(\"Train Accuracy   : {:2.2%}\".format(accuracy_train))\n",
    "print(\"Test Accuracy    : {:2.2%}\".format(accuracy_test))\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- accuracy here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- answer questions here, change to cell to markdown "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Writeup \n",
    "----- \n",
    "\n",
    "<div class=\"alert alert-info\"> üí° <strong> TODO </strong>\n",
    "    \n",
    "I'm not looking for anything long, just a short write up on what you did, what you thought was interesing about the data, how your rules performed, what can you infer about accuracy as a measure of performance vs. a confusion matrix? is Accuracy a good measure of classifier performance?\n",
    "<div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## - change cell to a markdown and write your response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
